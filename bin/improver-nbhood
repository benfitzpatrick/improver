#!/usr/bin/env python
# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# (C) British Crown Copyright 2017-2019 Met Office.
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its
#   contributors may be used to endorse or promote products derived from
#   this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
"""Script to run neighbourhood processing."""

import warnings

import numpy as np

from improver.argparser import ArgParser
from improver.constants import DEFAULT_PERCENTILES
from improver.nbhood.nbhood import (
    GeneratePercentilesFromANeighbourhood, NeighbourhoodProcessing)
from improver.nbhood.use_nbhood import (
    ApplyNeighbourhoodProcessingWithAMask,
    CollapseMaskedNeighbourhoodCoordinate
)
from improver.nbhood.recursive_filter import RecursiveFilter
from improver.utilities.pad_spatial import remove_cube_halo
from improver.utilities.load import load_cube
from improver.utilities.save import save_netcdf
from improver.wind_calculations.wind_direction import WindDirection


def main():
    """Load in arguments and get going."""
    parser = ArgParser(
        central_arguments=[
            "radius_required", "radii_lead_times", "halo_radius", "kernel",
            "degrees_as_complex", "sum_or_fraction", "mask_filepath",
            "coord_for_masking", "mask_weights_filepath",
            "landsea_mask_filepath", "input_filepath",
            "output_filepath", "no_recursive_filter",
            "alpha_x", "alpha_y", "iterations"],
        description=('Apply variants of neighbourhood processing (spatial '
                     'smoothing) to a file. Apart from different smoothing '
                     'kernels, such as circular vs square+squareness-filter '
                     '(recursive filter), there are three main masking '
                     'behaviours that can be applied, and a fourth no mask '
                     'case. The first is when the mask is simply over x/y, '
                     'in which case only the unmasked points will be '
                     'neighbourhood processed. The second is when the file '
                     'contains multiple masks along a particular given '
                     'mask coordinate. In this case, the user specifies the '
                     'name of the extra coordinate and this coordinate is '
                     'iterated over so each mask is applied in turn to '
                     'separate slices over the input data. These sliced '
                     'masked datasets are then concatenated, and by default '
                     'a weighted mean using an auxiliary weights file '
                     'is done to collapse over the mask coordinate to the '
                     'original dimensions. In the case where this masking '
                     'coordinate is topographic zone, the weights and values '
                     'can be generated with the improver generate-topography '
                     'CLIs. The third masking method is further to apply a '
                     'land and sea mask on top of the method used in the '
                     'second, multiple masks method. This allows land and sea '
                     'to be treated totally separately.')
     )
 
    args = parser.parse_args()

    if args.kernel in ["circular", "circular_weighted"]:
        if args.mask is not None:
            parser.wrong_args_error(
                'kernel!=square', 'mask')

        if args.landsea_mask is not None:
            parser.wrong_args_error(
                'kernel!=square', 'landsea_mask')

        if args.coord_for_masking is not None:
            parser.wrong_args_error(
                'kernel!=square', 'coord_for_masking')

        if args.degrees_as_complex:
            parser.error('Cannot process complex numbers with circular '
                         'neighbourhoods')

        if args.no_recursive_filter:
            parser.error('Recursive filter option is not applicable to '
                         'circular neighbourhoods.')

    if args.degrees_as_complex and not args.no_recursive_filter:
        parser.error('Cannot process complex numbers with recursive '
                     'filter')

    cube = load_cube(args.input_filepath)
    if args.degrees_as_complex:
        # convert cube data into complex numbers
        cube.data = WindDirection.deg_to_complex(cube.data)

    radius = args.radius
    if len(radius) == 1:
        radius = radius[0]
    elif not args.radii_lead_times:
        parser.error('Multiple radii given but no lead times specified')

    if args.kernel != "square":
        result = (
            NeighbourhoodProcessing(
                args.kernel, radius,
                lead_times=args.radii_lead_times).process(cube))
        save_netcdf(result, args.output_filepath)
        return

    weights_cube = None
    if args.mask_weights is not None:
        weights_cube = load_cube(args.mask_weights)


    coord_for_masking = args.coord_for_masking
    landsea_mode = False
    if args.mask:
        mask_cube = load_cube(args.mask)
    elif args.landsea_mask:
        landsea_mode = True
        mask_cube = load_cube(args.landsea_mask)
        if coord_for_masking is None:
            if weights_cube is not None:
                warnings.warn(
                    'A weights cube has been provided but will not be used '
                    'as there is no topographic zone coordinate to collapse.')
            landmask_cube = mask_cube
            landmask_data = landmask_cube.data
        else:
            if weights_cube is None and any(
                    [coord_for_masking in coord.name()
                     for coord in mask_cube.coords(dim_coords=True)]):
                raise Exception(
                    'A weights cube must be provided if using a landsea mask '
                    'of topographic zones to collapse the resulting vertical '
                    'dimension.'
                )
            if landsea_mode and weights_cube.attributes.get(
                    coord_for_masking + 's_include_seapoints') == 'True':
                raise ValueError('The weights cube must be masked to '
                                 'exclude sea points, but '
                                 'topographic_zones_include_seapoints '
                                 '= True')
            landmask_cube = weights_cube[0].copy(data=weights_cube[0].data.mask)
            landmask_cube.rename('land_binary_mask')
            landmask_cube.remove_coord(coord_for_masking)
            landmask_data = np.logical_not(landmask_cube.data)

        land_only = landmask_cube.copy(data=landmask_data.astype(int))
        sea_only = landmask_cube.copy(
            data=np.logical_not(landmask_data).astype(int))
        if land_only.data.max() > 0.0 and coord_for_masking is None:
            mask_cube = land_only
    else:
        mask_cube = None

    if coord_for_masking is None:
        result = NeighbourhoodProcessing(
            'square', radius, lead_times=args.radii_lead_times,
            sum_or_fraction=args.sum_or_fraction,
            re_mask=landsea_mode).process(
                cube, mask_cube)
    else:
        # Multiple masks.
        result = ApplyNeighbourhoodProcessingWithAMask(
            coord_for_masking, radius, lead_times=args.radii_lead_times,
            sum_or_fraction=args.sum_or_fraction).process(cube, mask_cube)

        # Collapse with the masking dimension.
        print("COLLLAPSE>>>>")
        if weights_cube is not None:
            print("landsea mode", landsea_mode, "weights_cube attributes", weights_cube.attributes, "seapoints?", weights_cube.attributes.get(coord_for_masking + 's_include_seapoints'))
            result = CollapseMaskedNeighbourhoodCoordinate(
                args.coord_for_masking, weights=weights_cube).process(result)

    if not args.no_recursive_filter:
        # Apply the recursive filter.

        alpha_x = None
        alphas_x_cube = None
        alpha_y = None
        alphas_y_cube = None

        try:
            alpha_x = float(args.alpha_x)
        except ValueError:
            alphas_x_cube = load_cube(args.alpha_x)

        try:
            alpha_y = float(args.alpha_y)
        except ValueError:
            alphas_y_cube = load_cube(args.alpha_y)

        result = RecursiveFilter(
            alpha_x=alpha_x, alpha_y=alpha_y,
            iterations=args.iterations).process(
                result, alphas_x=alphas_x_cube, alphas_y=alphas_y_cube,
                mask_cube=mask_cube)

    if args.landsea_mask:
        # Process the sea data separately.
        if sea_only.data.max() > 0.0:
            result_sea = NeighbourhoodProcessing(
                'square', radius, lead_times=args.radii_lead_times,
                sum_or_fraction=args.sum_or_fraction,
                re_mask=True).process(cube, sea_only)

        if land_only.data.max() == 0.0:
            result = result_sea
        else:
            # We have unmasked data for both land and sea.
            # Recombine cubes to be a single output.
            combined_data = (result.data.filled(0) +
                             result_sea.data.filled(0))
            result = result.copy(data=combined_data)

    if args.degrees_as_complex:
        # convert neighbourhooded cube back to degrees
        result.data = WindDirection.complex_to_deg(result.data)

    if args.halo_radius is not None:
        result = remove_cube_halo(result, args.halo_radius)

    save_netcdf(result, args.output_filepath)


if __name__ == "__main__":
    main()
